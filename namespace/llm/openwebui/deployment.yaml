apiVersion: apps/v1
kind: Deployment
metadata:
  name: openwebui
  namespace: llm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: openwebui
  template:
    metadata:
      labels:
        app: openwebui
    spec:
      containers:
        - name: openwebui
          image: ghcr.io/ggml-org/llama.cpp:server-intel
          imagePullPolicy: Always
          ports:
            - containerPort: 8080
              protocol: TCP
          env:
          - name: OPENAI_API_BASE_URL
            value: "http://vllm:3000/v1"
          volumeMounts:
            - name: config
              mountPath: /app/backend/data
          resources:
            requests:
              cpu: "1"
              memory: "2Gi"
            limits:
              cpu: "2"
              memory: "4Gi"
      volumes:
        - name: config
          persistentVolumeClaim:
            claimName: openwebui-config